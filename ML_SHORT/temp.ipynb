{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score,r2_score,mean_squared_error, classification_report,confusion_matrix,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Assign_1\n",
    "\n",
    "df = pd.read_csv(\"uber.csv\") \n",
    "df = df.drop(['Unnamed: 0', 'key', 'pickup_datetime'], axis=1)\n",
    "df = df.dropna()                       # Drop rows with any NaN values\n",
    "\n",
    "plt.figure(figsize=(10, 6))           \n",
    "sns.boxplot(data=df)                  \n",
    "plt.show() \n",
    "\n",
    "#TO REMOVE OUTLIERS\n",
    "for col in df.columns:                 \n",
    "    Q1 = df[col].quantile(0.25)       \n",
    "    Q3 = df[col].quantile(0.75)        \n",
    "    IQR = Q3 - Q1                     \n",
    "    \n",
    "    lb = Q1 - 1.5 * IQR                \n",
    "    ub = Q3 + 1.5 * IQR                \n",
    "    \n",
    "    df = df[(df[col] >= lb) & (df[col] <= ub)]  # Remove rows outside the bounds\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "\n",
    "sns.heatmap(data=df.corr(), annot=True)  # Plot the correlation heatmap with annotations\n",
    "plt.show()  \n",
    "\n",
    "X = df[[\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\", \"passenger_count\"]]\n",
    "Y = df[\"fare_amount\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "model = LinearRegression() \n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2score = r2_score(Y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, y_pred))\n",
    "\n",
    "model1 = RandomForestRegressor() #-->> rest is same \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign_2\n",
    "\n",
    "df = df.drop(['Email No.'], axis=1)\n",
    "X=df.drop(['Prediction'],axis=1)\n",
    "Y=df['Prediction']\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "classification_report(y_test, y_pred_knn)\n",
    "cnf=confusion_matrix(y_test, y_pred)\n",
    "cm = ConfusionMatrixDisplay(confusion_matrix=cnf, display_labels=['Spam', 'Not Spam'])\n",
    "cm.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign_3\n",
    "label_encoder = LabelEncoder()\n",
    "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
    "\n",
    "X = df.drop('Exited', axis = 1) # Features\n",
    "Y = df['Exited'] # Target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_test = scaler.transform(x_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(activation='relu', units=32, input_dim=X_train.shape[1]))  # Input layer with more neurons\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign_4\n",
    "\n",
    "def func(x):\n",
    "    return (x + 3)**2\n",
    "\n",
    "def derivative(x):\n",
    "    return 2 * (x + 3)\n",
    "\n",
    "gd=[]#gred descent\n",
    "\n",
    "def gradient_descent(starting_x, learning_rate, num_iterations):\n",
    "    x = starting_x  # Starting point\n",
    "    gd.append(starting_x)\n",
    "    for i in range(num_iterations):\n",
    "        grad = derivative(x)  # slope at x\n",
    "        x = x - learning_rate * grad  # Update x based on gradient\n",
    "        gd.append(x)\n",
    "        print(f\"Iteration {i+1}: x = {x}, f(x) = {func(x)}\")\n",
    "    \n",
    "    return x\n",
    "\n",
    "sns.scatterplot(gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "K = range(1, 11)\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)  \n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    \n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(K, inertia)\n",
    "\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()\n",
    "\n",
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "df_cleaned['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "print(df_cleaned[['SALES', 'QUANTITYORDERED', 'PRICEEACH', 'Cluster']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
